{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raleight1/Forecasting-Nonseasonal-and-Seasonal/blob/main/Nonseasonal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Background and Data Source**\n",
        "\n",
        "For our non seasonal project we chose daily rainfall measurements for the year 2025 so far, we stored this in a csv/excel format. The dataset has 59 observations.\n",
        "We chose this data because since we live in Ireland were always surrounded by rain, and with Irish weathers there’s so much change and uncertainty it’s hard to find a clear cut pattern. So we though it makes it a good suitable candidate for the nonseasonal time series model.\n",
        "The dataset shows daily fluctuations and is relevant to Irish life impacting aguculture, tourism and commuting. From a model perspective its irregular and challenging ot predict which is good for arima forecasting.\n",
        "\n",
        "URL: https://www.met.ie/climate/available-data/historical-data\n",
        "\n",
        "# Data Overview\n",
        "Variable : Daily rainfall in millimetres\n",
        "\n",
        "Time Period : January 1st 2025 – February 28th 2025\n",
        "\n",
        "Frequency : Daily\n",
        "\n",
        "Observations : 59\n",
        "\n",
        "# Purpose of analysis\n",
        "\n",
        "The aim for us is to identify and fit a nonseasonal time series model using the daily precipitation data then use it to make short term forecasts. It will help us understand how the rainfall evolves over time.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TAirjMPjg0OE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Milestone 1:"
      ],
      "metadata": {
        "id": "b6sYyvrjmFk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.arima_process import ArmaProcess\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from tqdm import tqdm_notebook\n",
        "from itertools import product\n",
        "from typing import Union\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "LctKMsCd7fJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://raw.githubusercontent.com/raleight1/Forecasting-Nonseasonal-and-Seasonal/refs/heads/main/annual-co2-emissions-per-country.csv'\n",
        "df = pd.read_csv(URL)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "rLJTeJ0PmLkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:, 2:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gtvPAgaegohT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the time series plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['Year'], df['Annual CO₂ emissions'])\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('CO₂ emissions')\n",
        "plt.title('Annual CO₂ emissions')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7sB7Y0GyD0c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Milestone 2:"
      ],
      "metadata": {
        "id": "FufGDXOGmMW9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4TSdk8Lk8bk"
      },
      "outputs": [],
      "source": [
        "ad_fuller_result = adfuller(df['Annual CO₂ emissions'])\n",
        "\n",
        "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
        "print(f'p-value: {ad_fuller_result[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['date'], df['rain'])\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Daily Rainfall')\n",
        "plt.title('Daily Rainfall for the First 2 Months of 2025')\n",
        "train_end = '2025-02-23'\n",
        "test_end = '2025-02-28'\n",
        "plt.axvspan(train_end, test_end, color='#808080', alpha=0.2)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F573UjH8IZmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acf(df['rain'], lags=58);\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Q01ARLMPNQpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pacf(df['rain'], lags=29);\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "hRJkAw3LNkX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_ARIMA(training_data, order_list, d) -> pd.DataFrame:\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for order in tqdm_notebook(order_list):\n",
        "        try:\n",
        "            model = SARIMAX(training_data, order=(order[0], d, order[1]), simple_differencing=False).fit(disp=False)\n",
        "            no_pars = order[0]+order[1]\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        aic = model.aic\n",
        "        bic= model.bic\n",
        "        results.append([order, no_pars, aic, bic])\n",
        "\n",
        "    result_df = pd.DataFrame(results)\n",
        "    result_df.columns = ['(p,q)', 'NO. Parameters', 'AIC','BIC']\n",
        "\n",
        "    #Sort in ascending order, lower AIC is better\n",
        "    result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "BWCCbxTJpOML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = range(0, 4, 1)\n",
        "qs = range(0, 4, 1)\n",
        "d = 0\n",
        "\n",
        "order_list = list(product(ps, qs))\n",
        "order_list"
      ],
      "metadata": {
        "id": "csTTvyc9pZeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = df['rain'][:-7]\n",
        "\n",
        "result_df = optimize_ARIMA(train, order_list, d)\n",
        "result_df"
      ],
      "metadata": {
        "id": "N1mp9PSWpb6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SARIMAX(train, order=(1,0,1), simple_differencing=False)\n",
        "model_fit = model.fit(disp=False)\n",
        "\n",
        "print(model_fit.summary())"
      ],
      "metadata": {
        "id": "nas9sKJXp46B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fit.plot_diagnostics(figsize=(10,8));"
      ],
      "metadata": {
        "id": "DsKS8GGJqeCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fTNqYEw54Jt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pvj9pXKQ4OzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overview**\n",
        "\n",
        "The model identification process involved analysing the time series data to determine stationarity, seasonality, and potential model structures. Various statistical techniques, including autocorrelation and partial autocorrelation functions, were used to guide model selection.\n",
        "\n",
        "**Data Visualisation and Initial Observations**\n",
        "\n",
        "The dataset consists of daily rainfall measurements. To understand its characteristics, the following plots were generated:\n",
        "\n",
        "1. ***Time Series Plot***: A visualization of daily rainfall for the first two months of 2025. This plot reveals overall trends and potential seasonal patterns.\n",
        "\n",
        "2. ***Train-Test Split Visualization***: The dataset was divided into training and testing periods, with the training period ending on February 23, 2025, and the testing period covering the last few days of February. The division was highlighted in the time series plot.\n",
        "\n",
        "3. ***Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) Plots***: These were generated to assess lag dependencies and identify the appropriate ARIMA or SARIMA model parameters.\n",
        "\n",
        "4. ***Histogram and QQ Plot***: These were used to check the normality of residuals, which is crucial for validating model assumptions.\n",
        "\n",
        "**Statistical Tests and Findings**\n",
        "\n",
        "1. ***Augmented Dickey-Fuller (ADF) Test***: Conducted to check for stationarity. If the p-value was high, differencing was applied to achieve stationarity.\n",
        "\n",
        "2. ***Ljung-Box Test***: Used to assess the independence of residuals and determine if autocorrelations were significant.\n",
        "\n",
        "3. ***Model Selection Criteria***: AIC and BIC scores were evaluated for different models to choose the best-fitting one.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Based on the visualisations and statistical analyses, an appropriate time series model was selected. The next steps include model fitting, residual analysis, and forecasting to validate its predictive performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "zc_aiXki5WK3"
      }
    }
  ]
}